{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectYuni_hate_speech.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW75EA3kfsHX"
      },
      "source": [
        "### load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C6yGb5AfVvo",
        "outputId": "39b933c2-fae8-4466-ccc1-c5882ceab357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import TweetTokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWfm_LD0fhdW"
      },
      "source": [
        "data = pd.read_csv('labeled_data.csv')\n",
        "data.head()\n",
        "\n",
        "new_columns = data.columns.values\n",
        "new_columns[0] = 'id'\n",
        "data.columns = new_columns\n",
        "data.set_index('id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adn9V08kfjdt",
        "outputId": "52647407-21bd-49c1-a544-324072d6965f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "# drop unnecessary columns \n",
        "data.drop(['count','hate_speech','offensive_language','neither'], axis='columns', inplace=True)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25291</th>\n",
              "      <td>1</td>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25292</th>\n",
              "      <td>2</td>\n",
              "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25294</th>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25295</th>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25296</th>\n",
              "      <td>2</td>\n",
              "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class                                              tweet\n",
              "id                                                             \n",
              "0          2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1          1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2          1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3          1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4          1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "...      ...                                                ...\n",
              "25291      1  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
              "25292      2  you've gone and broke the wrong heart baby, an...\n",
              "25294      1  young buck wanna eat!!.. dat nigguh like I ain...\n",
              "25295      1              youu got wild bitches tellin you lies\n",
              "25296      2  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
              "\n",
              "[24783 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb76c1z7fwrs"
      },
      "source": [
        "### preprocess the text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IfPHScYfq9F"
      },
      "source": [
        "bad_symbols_re = re.compile('[^0-9a-z #@://]')\n",
        "stopwords_re = set(stopwords.words('english'))\n",
        "twitter_username_re = re.compile(r'@([A-Za-z0-9#]+)')\n",
        "hashtag_re = re.compile(r'#([0-9]+)')\n",
        "http_re = re.compile(r'https?:\\/\\/.*[\\r\\n]*')\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(bad_symbols_re,'',text)\n",
        "  text = re.sub(twitter_username_re,'',text)\n",
        "  text = re.sub(hashtag_re,'',text)\n",
        "  text = re.sub(http_re,'',text)\n",
        "  text = ' '.join([word for word in text.split() if word not in stopwords_re])\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uwArjwCf1X-",
        "outputId": "fecd8b15-7883-480f-b6f5-94627c8d9f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        }
      },
      "source": [
        "data['tweet'] = data['tweet'].apply(lambda x: clean_text(x))\n",
        "data.head(25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>rt : woman shouldnt complain cleaning house am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rt : boy dats coldtyga dwn bad cuffin dat hoe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>rt dawg rt : ever fuck bitch start cry confuse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>rt : look like tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>rt : shit hear might true might faker bitch to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>: shit blows meclaim faithful somebody still f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>: sit hate another bitch got much shit going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>: cause im tired big bitches coming us skinny ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>amp might get ya bitch back amp thats</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>:hobbies include: fighting mariambitch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>keeks bitch curves everyone lol walked convers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>murda gang bitch gang land</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>hoes smoke losers yea go ig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>bad bitches thing like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>bitch get</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>bitch nigga miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>bitch plz whatever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>bitch love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>bitches get cut everyday b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>black bottle amp bad bitch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>broke bitch cant tell nothing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>cancel bitch like nino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>cant see hoes wont change</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>fuck bitch dont even suck dick kermit videos b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>got ya bitch tip toeing hardwood floors</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    class                                              tweet\n",
              "id                                                          \n",
              "0       2  rt : woman shouldnt complain cleaning house am...\n",
              "1       1  rt : boy dats coldtyga dwn bad cuffin dat hoe ...\n",
              "2       1  rt dawg rt : ever fuck bitch start cry confuse...\n",
              "3       1                              rt : look like tranny\n",
              "4       1  rt : shit hear might true might faker bitch to...\n",
              "5       1  : shit blows meclaim faithful somebody still f...\n",
              "6       1       : sit hate another bitch got much shit going\n",
              "7       1  : cause im tired big bitches coming us skinny ...\n",
              "8       1              amp might get ya bitch back amp thats\n",
              "9       1             :hobbies include: fighting mariambitch\n",
              "10      1  keeks bitch curves everyone lol walked convers...\n",
              "11      1                         murda gang bitch gang land\n",
              "12      1                        hoes smoke losers yea go ig\n",
              "13      1                             bad bitches thing like\n",
              "14      1                                          bitch get\n",
              "15      1                                   bitch nigga miss\n",
              "16      1                                 bitch plz whatever\n",
              "17      1                                         bitch love\n",
              "18      1                         bitches get cut everyday b\n",
              "19      1                         black bottle amp bad bitch\n",
              "20      1                      broke bitch cant tell nothing\n",
              "21      1                             cancel bitch like nino\n",
              "22      1                          cant see hoes wont change\n",
              "23      1  fuck bitch dont even suck dick kermit videos b...\n",
              "24      1            got ya bitch tip toeing hardwood floors"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I2NV2S0h8O-",
        "outputId": "3125c6a5-e5f6-4429-e732-5b5ab85693a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "data.loc[data['class'] == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rt : boy dats coldtyga dwn bad cuffin dat hoe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>rt dawg rt : ever fuck bitch start cry confuse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>rt : look like tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>rt : shit hear might true might faker bitch to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>: shit blows meclaim faithful somebody still f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25287</th>\n",
              "      <td>1</td>\n",
              "      <td>really care bout dis bitch dick yo feelings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25288</th>\n",
              "      <td>1</td>\n",
              "      <td>worried bout bitches need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25291</th>\n",
              "      <td>1</td>\n",
              "      <td>yous muthafin lie : right tl trash mine bible ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25294</th>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25295</th>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin lies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19190 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class                                              tweet\n",
              "id                                                             \n",
              "1          1  rt : boy dats coldtyga dwn bad cuffin dat hoe ...\n",
              "2          1  rt dawg rt : ever fuck bitch start cry confuse...\n",
              "3          1                              rt : look like tranny\n",
              "4          1  rt : shit hear might true might faker bitch to...\n",
              "5          1  : shit blows meclaim faithful somebody still f...\n",
              "...      ...                                                ...\n",
              "25287      1        really care bout dis bitch dick yo feelings\n",
              "25288      1                          worried bout bitches need\n",
              "25291      1  yous muthafin lie : right tl trash mine bible ...\n",
              "25294      1  young buck wanna eat dat nigguh like aint fuck...\n",
              "25295      1                  youu got wild bitches tellin lies\n",
              "\n",
              "[19190 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6gVoB3Tf4CG"
      },
      "source": [
        "### feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9mAk6GUf60U",
        "outputId": "28b8b259-107a-467f-b0b1-5d7af0b5d74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data[\"tweet\"], data[\"class\"], test_size = 0.2, random_state = 42)\n",
        "len(x_train), len(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19826, 4957)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUaGipzRf_Qr"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "tok = TweetTokenizer(\n",
        "    preserve_case = False,\n",
        "    reduce_len = True,\n",
        "    strip_handles = True,\n",
        ")\n",
        "\n",
        "def tfidf_features(X_train, X_test):\n",
        "  tfidf_vectorizer = TfidfVectorizer(\n",
        "      token_pattern='(\\S+)',\n",
        "      decode_error = 'ignore',\n",
        "      strip_accents = 'unicode',\n",
        "      tokenizer = tok.tokenize,\n",
        "      stop_words = stop_words,\n",
        "      max_features = 5000, \n",
        "      ngram_range=(1, 3),\n",
        "      sublinear_tf = True)\n",
        "  X_train = tfidf_vectorizer.fit_transform(X_train)  \n",
        "  X_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, tfidf_vectorizer.vocabulary_\n",
        "\n",
        "X_train_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(x_train, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L2-j5PFgDJI"
      },
      "source": [
        "### find the best model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3JdXnT7gHb9"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "def find_best_model_using_gridsearchCV(X,y):\n",
        "  algos = {\n",
        "      'logistic_regression':{\n",
        "          'model': LogisticRegression(),\n",
        "          'params':{\n",
        "              'solver' : ['newton-cg','sag','lbfgs'],\n",
        "              'C':[1,2]\n",
        "          }\n",
        "      },\n",
        "      'svm':{\n",
        "          'model': SVC(),\n",
        "          'params' :{\n",
        "              'C':[1,2],\n",
        "              'kernel':['poly','rbf','sigmoid']\n",
        "          }\n",
        "      },\n",
        "      'naive_bayes':{\n",
        "          'model': MultinomialNB(),\n",
        "          'params':{\n",
        "              'fit_prior':[True,False]\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "\n",
        "  scores=[]\n",
        "  cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "  for algo_name, config in algos.items():\n",
        "    gs = GridSearchCV(config['model'], config['params'],cv=cv, return_train_score=False)\n",
        "    sm = SMOTE(random_state = 2) \n",
        "    X_train_res, y_train_res = sm.fit_sample(X,y)\n",
        "    gs.fit(X_train_res,y_train_res)\n",
        "    scores.append({\n",
        "        'model': algo_name,\n",
        "        'best_score':gs.best_score_,\n",
        "        'best_params':gs.best_params_\n",
        "    })\n",
        "  return pd.DataFrame(scores, columns=['model','best_score','best_params'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc20inYLgw9W",
        "outputId": "2c248fe8-a27b-47e7-e075-9b6ccbba4216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "find_best_model_using_gridsearchCV(X_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>best_score</th>\n",
              "      <th>best_params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logistic_regression</td>\n",
              "      <td>0.914509</td>\n",
              "      <td>{'C': 2, 'solver': 'lbfgs'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>svm</td>\n",
              "      <td>0.956875</td>\n",
              "      <td>{'C': 2, 'kernel': 'rbf'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>0.879783</td>\n",
              "      <td>{'fit_prior': True}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model  best_score                  best_params\n",
              "0  logistic_regression    0.914509  {'C': 2, 'solver': 'lbfgs'}\n",
              "1                  svm    0.956875    {'C': 2, 'kernel': 'rbf'}\n",
              "2          naive_bayes    0.879783          {'fit_prior': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArxZjTDnqDom"
      },
      "source": [
        "**Training and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwQ5FgjxqFD2",
        "outputId": "b3a7045b-bba0-4525-f22e-1f1c732f7be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import SMOTE \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "svm_clf = SVC(C=2, kernel='rbf')\n",
        "lg_clf = LogisticRegression(C=2, solver='lbfgs')\n",
        "sm = SMOTE(random_state = 2) \n",
        "\n",
        "# traininng\n",
        "X_train_res, y_train_res = sm.fit_sample(X_train_tfidf,y_train)\n",
        "lg_clf.fit(X_train_res, y_train_res)\n",
        "y_pred = lg_clf.predict(X_test_tfidf)\n",
        "\n",
        "# evaluation\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2', 'Class 3']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[ 153  101   36]\n",
            " [ 327 3319  186]\n",
            " [  49   62  724]]\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 1       0.29      0.53      0.37       290\n",
            "     Class 2       0.95      0.87      0.91      3832\n",
            "     Class 3       0.77      0.87      0.81       835\n",
            "\n",
            "    accuracy                           0.85      4957\n",
            "   macro avg       0.67      0.75      0.70      4957\n",
            "weighted avg       0.88      0.85      0.86      4957\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}